{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "bdc55088-bc57-497d-919b-1b58fa9b6f23",
   "metadata": {},
   "source": [
    "# Exercise 3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aba94-c4d8-435c-9b88-5b23f78e6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "import torch\n",
    "print(\"torch version:\", version(\"torch\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904449b5-fdc2-4bd5-9d27-93562d55ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89],  # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66],  # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64],  # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33],  # with     (x^4)\n",
    "   [0.77, 0.25, 0.10],  # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]]  # step     (x^6)\n",
    ")\n",
    "d_in, d_out = 3, 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e83296-ebd0-4730-992d-9a424590fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f5c99-fd8a-409f-83f9-c24c47b65f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=False)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350416a3-aed3-4eb9-ba8c-c8b18fba505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_v1.W_query = torch.nn.Parameter(sa_v2.W_query.weight.T)\n",
    "sa_v1.W_key = torch.nn.Parameter(sa_v2.W_key.weight.T)\n",
    "sa_v1.W_value = torch.nn.Parameter(sa_v2.W_value.weight.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a2def-c622-4406-a871-4c7309f5e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_v1(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee4a63-ae0a-4253-b531-9f53e7e1ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_v2(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8fd69-68ab-4558-a08c-5e66d1c54bd7",
   "metadata": {},
   "source": [
    "# Exercise 3.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d3ef5-04a7-49ec-ac0a-a6e7c6b92eee",
   "metadata": {},
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "d_out = 1\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827e3d2-59ac-4e5d-bbd7-e4d99da2b806",
   "metadata": {},
   "source": [
    "tensor([[[-9.1476e-02,  3.4164e-02],\n",
    "         [-2.6796e-01, -1.3427e-03],\n",
    "         [-4.8421e-01, -4.8909e-02],\n",
    "         [-6.4808e-01, -1.0625e-01],\n",
    "         [-8.8380e-01, -1.7140e-01],\n",
    "         [-1.4744e+00, -3.4327e-01]],\n",
    "\n",
    "        [[-9.1476e-02,  3.4164e-02],\n",
    "         [-2.6796e-01, -1.3427e-03],\n",
    "         [-4.8421e-01, -4.8909e-02],\n",
    "         [-6.4808e-01, -1.0625e-01],\n",
    "         [-8.8380e-01, -1.7140e-01],\n",
    "         [-1.4744e+00, -3.4327e-01]]], grad_fn=<CatBackward0>)\n",
    "context_vecs.shape: torch.Size([2, 6, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d5886-1061-4f2c-ac4a-bba2a82999f5",
   "metadata": {},
   "source": [
    "# Exercise 3.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232af533-ebc1-44b2-97d4-69abf5fba71f",
   "metadata": {},
   "source": [
    "\n",
    "context_length = 1024\n",
    "d_in, d_out = 768, 768\n",
    "num_heads = 12\n",
    "\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757e8c4-652c-413a-b329-34d1847cd6be",
   "metadata": {},
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(mha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61981653-37ee-4273-b833-480d96c1b2e5",
   "metadata": {},
   "source": [
    "2360064  # (2.36 M)\n"
   ]
=======
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf1271-a58e-458d-b4bc-a5a6440ba1ad",
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 29d9fb2 (Completed Exercises 4.2 and 4.3)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
